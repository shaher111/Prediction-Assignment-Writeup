knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
install.packages("knitr")
rawtrainSet <- read.csv(file ="pml-training.csv",na.strings = c("NA","#DIV/0!"))
testSet <- read.csv(file="pml-testing.csv",na.strings = c("NA","#DIV/0!"))
rawtrainSet <- read.csv(file ="pml-training.csv",na.strings = c("NA","#DIV/0!"))
testSet <- read.csv(file="pml-testing.csv",na.strings = c("NA","#DIV/0!"))
finalpred <- predict(mod3,testSet[,-54])
knitr::opts_chunk$set(echo = TRUE)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
install.packages("caret")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
set.seed(1234)
rawtrainSet <- read.csv(file ="pml-training.csv",na.strings = c("NA","#DIV/0!"))
testSet <- read.csv(file="pml-testing.csv",na.strings = c("NA","#DIV/0!"))
dim(rawtrainSet)
dim(testSet)
rawtrainSet<-rawtrainSet[,colSums(is.na(rawtrainSet)) == 0]
testSet <-testSet[,colSums(is.na(testSet)) == 0]
sum(!complete.cases(rawtrainSet))
sum(!complete.cases(testSet))
cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp","num_window","new_window")
rawtrainSet <- rawtrainSet[,-which(names(rawtrainSet)%in% cols)]
testSet <- testSet[,-which(names(testSet)%in% cols)]
split <- 0.80
trainind <-  createDataPartition(rawtrainSet$classe, p=split, list=FALSE)
trainSet <- rawtrainSet[trainind,]
validSet <- rawtrainSet[-trainind,]
library(randomForest)
install.packages("randomForest")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
set.seed(1234)
rawtrainSet <- read.csv(file ="pml-training.csv",na.strings = c("NA","#DIV/0!"))
testSet <- read.csv(file="pml-testing.csv",na.strings = c("NA","#DIV/0!"))
dim(rawtrainSet)
dim(testSet)
rawtrainSet<-rawtrainSet[,colSums(is.na(rawtrainSet)) == 0]
testSet <-testSet[,colSums(is.na(testSet)) == 0]
sum(!complete.cases(rawtrainSet))
sum(!complete.cases(testSet))
cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp","num_window","new_window")
rawtrainSet <- rawtrainSet[,-which(names(rawtrainSet)%in% cols)]
testSet <- testSet[,-which(names(testSet)%in% cols)]
split <- 0.80
trainind <-  createDataPartition(rawtrainSet$classe, p=split, list=FALSE)
trainSet <- rawtrainSet[trainind,]
validSet <- rawtrainSet[-trainind,]
library(randomForest)
library(nnet)
split <- 0.80
trainIndex <- createDataPartition(trainSet$classe, p=split, list=FALSE)
traincross <- trainSet[trainIndex, ]
testcross <- trainSet[-trainIndex,]
mod1 <- randomForest(classe ~ ., data=traincross,method="class")
mod2 <- multinom(classe ~ ., data=traincross, maxit =500, trace=T)
mod3 <- train(classe ~ ., data=traincross, method="lda",na.action = na.exclude)
install.packages("e1071")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
set.seed(1234)
rawtrainSet <- read.csv(file ="pml-training.csv",na.strings = c("NA","#DIV/0!"))
testSet <- read.csv(file="pml-testing.csv",na.strings = c("NA","#DIV/0!"))
dim(rawtrainSet)
dim(testSet)
rawtrainSet<-rawtrainSet[,colSums(is.na(rawtrainSet)) == 0]
testSet <-testSet[,colSums(is.na(testSet)) == 0]
sum(!complete.cases(rawtrainSet))
sum(!complete.cases(testSet))
cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp","num_window","new_window")
rawtrainSet <- rawtrainSet[,-which(names(rawtrainSet)%in% cols)]
testSet <- testSet[,-which(names(testSet)%in% cols)]
split <- 0.80
trainind <-  createDataPartition(rawtrainSet$classe, p=split, list=FALSE)
trainSet <- rawtrainSet[trainind,]
validSet <- rawtrainSet[-trainind,]
library(randomForest)
library(nnet)
split <- 0.80
trainIndex <- createDataPartition(trainSet$classe, p=split, list=FALSE)
traincross <- trainSet[trainIndex, ]
testcross <- trainSet[-trainIndex,]
mod1 <- randomForest(classe ~ ., data=traincross,method="class")
mod2 <- multinom(classe ~ ., data=traincross, maxit =500, trace=T)
mod3 <- train(classe ~ ., data=traincross, method="lda",na.action = na.exclude)
pred1 <- predict(mod1,testcross)
pred2 <- predict(mod2,testcross)
pred3 <- predict(mod3,testcross)
accuracy1 <- sum(pred1==testcross$classe)/length(pred1)
accuracy2 <- sum(pred2==testcross$classe)/length(pred2)
accuracy3 <- sum(pred3==testcross$classe)/length(pred3)
accuracy1 #for random forest
accuracy2 #for multinormial logistic regression
accuracy3 #for linear discriminant analysis
finalmod<- randomForest(classe ~. ,data=trainSet,method="class")
pred <- predict(finalmod,validSet,method="class")
accuracy <- sum(pred==validSet$classe)/length(pred)
1-accuracy
finalpred <- predict(mod3,testSet[,-54])
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(e1071)
library(rattle)
install.packages("rattle")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(e1071)
library(rattle)
library(randomForest)
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!exists("Training Data.csv")){
download.file(trainURL, "Training Data.csv")
}
if(!exists("Testing Data.csv")){
download.file(testURL, "Testing Data.csv")
}
training <- read.csv("Training Data.csv", na.strings = c("NA",""))
testing <- read.csv("Testing Data.csv", na.strings = c("NA",""))
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
trainingClean <- training[,-c(1:7)]
testingClean <- testing[,-c(1:7)]
set.seed(8)
inTrain <- createDataPartition(y=trainingClean$classe, p=0.7, list=FALSE)
train <- trainingClean[inTrain,]
test <- trainingClean[-inTrain,]
set.seed(8)
modFit1 <- train(classe ~. , method="rpart", data=train, trControl = trainControl(method="cv", number=5))
fancyRpartPlot(modFit1$finalModel)
pred1 <- predict(modFit1, newdata=test)
confRpart <- confusionMatrix(test$classe, pred1)
confRpart$overall[1]
acc <- confRpart$overall[1]
set.seed(8)
modFit2 <- train(classe ~. , method="rf", data=train)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
set.seed(1234)
rawtrainSet <- read.csv(file ="pml-training.csv",na.strings = c("NA","#DIV/0!"))
testSet <- read.csv(file="pml-testing.csv",na.strings = c("NA","#DIV/0!"))
dim(rawtrainSet)
dim(testSet)
rawtrainSet<-rawtrainSet[,colSums(is.na(rawtrainSet)) == 0]
testSet <-testSet[,colSums(is.na(testSet)) == 0]
sum(!complete.cases(rawtrainSet))
sum(!complete.cases(testSet))
cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp","num_window","new_window")
rawtrainSet <- rawtrainSet[,-which(names(rawtrainSet)%in% cols)]
testSet <- testSet[,-which(names(testSet)%in% cols)]
split <- 0.80
trainind <-  createDataPartition(rawtrainSet$classe, p=split, list=FALSE)
trainSet <- rawtrainSet[trainind,]
validSet <- rawtrainSet[-trainind,]
library(randomForest)
library(nnet)
split <- 0.80
trainIndex <- createDataPartition(trainSet$classe, p=split, list=FALSE)
traincross <- trainSet[trainIndex, ]
testcross <- trainSet[-trainIndex,]
mod1 <- randomForest(classe ~ ., data=traincross,method="class")
mod2 <- multinom(classe ~ ., data=traincross, maxit =500, trace=T)
mod3 <- train(classe ~ ., data=traincross, method="lda",na.action = na.exclude)
pred1 <- predict(mod1,testcross)
pred2 <- predict(mod2,testcross)
pred3 <- predict(mod3,testcross)
accuracy1 <- sum(pred1==testcross$classe)/length(pred1)
accuracy2 <- sum(pred2==testcross$classe)/length(pred2)
accuracy3 <- sum(pred3==testcross$classe)/length(pred3)
accuracy1 #for random forest
accuracy2 #for multinormial logistic regression
accuracy3 #for linear discriminant analysis
finalmod<- randomForest(classe ~. ,data=trainSet,method="class")
pred <- predict(finalmod,validSet,method="class")
accuracy <- sum(pred==validSet$classe)/length(pred)
1-accuracy
finalpred <- predict(mod3,testSet[,-54])
knitr::opts_chunk$set(echo = TRUE)
library(caret)
set.seed(1234)
rawtrainSet <- read.csv(file ="pml-training.csv",na.strings = c("NA","#DIV/0!"))
testSet <- read.csv(file="pml-testing.csv",na.strings = c("NA","#DIV/0!"))
dim(rawtrainSet)
dim(testSet)
rawtrainSet<-rawtrainSet[,colSums(is.na(rawtrainSet)) == 0]
testSet <-testSet[,colSums(is.na(testSet)) == 0]
sum(!complete.cases(rawtrainSet))
sum(!complete.cases(testSet))
cols <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp","num_window","new_window")
rawtrainSet <- rawtrainSet[,-which(names(rawtrainSet)%in% cols)]
testSet <- testSet[,-which(names(testSet)%in% cols)]
split <- 0.80
trainind <-  createDataPartition(rawtrainSet$classe, p=split, list=FALSE)
trainSet <- rawtrainSet[trainind,]
validSet <- rawtrainSet[-trainind,]
library(randomForest)
library(nnet)
split <- 0.80
trainIndex <- createDataPartition(trainSet$classe, p=split, list=FALSE)
traincross <- trainSet[trainIndex, ]
testcross <- trainSet[-trainIndex,]
mod1 <- randomForest(classe ~ ., data=traincross,method="class")
mod2 <- multinom(classe ~ ., data=traincross, maxit =500, trace=T)
mod3 <- train(classe ~ ., data=traincross, method="lda",na.action = na.exclude)
pred1 <- predict(mod1,testcross)
pred2 <- predict(mod2,testcross)
pred3 <- predict(mod3,testcross)
accuracy1 <- sum(pred1==testcross$classe)/length(pred1)
accuracy2 <- sum(pred2==testcross$classe)/length(pred2)
accuracy3 <- sum(pred3==testcross$classe)/length(pred3)
accuracy1 #for random forest
accuracy2 #for multinormial logistic regression
accuracy3 #for linear discriminant analysis
finalmod<- randomForest(classe ~. ,data=trainSet,method="class")
pred <- predict(finalmod,validSet,method="class")
accuracy <- sum(pred==validSet$classe)/length(pred)
1-accuracy
finalpred <- predict(mod3,testSet[,-54])
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(DBI)
con <- dbConnect(odbc::odbc(), "Excel Files")
